{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "from sklearn.experimental import enable_halving_search_cv \n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "import json\n",
    "from sklearn.model_selection import KFold \n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_path = 'data/input/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_train_data = pd.read_csv(input_path + 'train_data_prepped.csv').fillna('')\n",
    "all_test_data = pd.read_csv(input_path + 'test_data_prepped.csv').fillna('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "positive    520436\n",
       "negative    519803\n",
       "neutral         84\n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_target = pd.read_csv(input_path + 'train_results.csv')\n",
    "train_target['target'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_target['target'] = [0 if t == 'negative' else 2 if t == 'positive' else 2 for t in train_target['target'].values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_train_data['target'] = train_target['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2    520520\n",
       "0    519803\n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_train_data['target'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "set text parameters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X = all_train_data.iloc[:, :-1]\n",
    "train_y  = all_train_data.iloc[:, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>cat</th>\n",
       "      <th>text_no_punc</th>\n",
       "      <th>text_no_numerals</th>\n",
       "      <th>text_no_sw</th>\n",
       "      <th>text_porter_stemmed</th>\n",
       "      <th>text_lancaster_stemmed</th>\n",
       "      <th>text_lemmatized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>anyway im getting of for a while</td>\n",
       "      <td>train</td>\n",
       "      <td>anyway im getting of for a while</td>\n",
       "      <td>anyway im getting of for a while</td>\n",
       "      <td>anyway im getting</td>\n",
       "      <td>anyway im get</td>\n",
       "      <td>anyway im get</td>\n",
       "      <td>anyway im getting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>my red, apache isn't feelin too well this morn...</td>\n",
       "      <td>train</td>\n",
       "      <td>my red apache isnt feelin too well this mornin...</td>\n",
       "      <td>my red apache isnt feelin too well this mornin...</td>\n",
       "      <td>red apache feelin well morning httpmypictmen</td>\n",
       "      <td>red apach feelin well morn httpmypictmen</td>\n",
       "      <td>red apach feelin wel morn httpmypictmen</td>\n",
       "      <td>red apache feelin well morning httpmypictmen</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                               text    cat  \\\n",
       "0   0                  anyway im getting of for a while   train   \n",
       "1   1  my red, apache isn't feelin too well this morn...  train   \n",
       "\n",
       "                                        text_no_punc  \\\n",
       "0                  anyway im getting of for a while    \n",
       "1  my red apache isnt feelin too well this mornin...   \n",
       "\n",
       "                                    text_no_numerals  \\\n",
       "0                  anyway im getting of for a while    \n",
       "1  my red apache isnt feelin too well this mornin...   \n",
       "\n",
       "                                     text_no_sw  \\\n",
       "0                             anyway im getting   \n",
       "1  red apache feelin well morning httpmypictmen   \n",
       "\n",
       "                        text_porter_stemmed  \\\n",
       "0                             anyway im get   \n",
       "1  red apach feelin well morn httpmypictmen   \n",
       "\n",
       "                    text_lancaster_stemmed  \\\n",
       "0                            anyway im get   \n",
       "1  red apach feelin wel morn httpmypictmen   \n",
       "\n",
       "                                text_lemmatized  \n",
       "0                             anyway im getting  \n",
       "1  red apache feelin well morning httpmypictmen  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_X.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    2\n",
       "1    0\n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_y.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_sizes = [100, 1_000, 10_000]\n",
    "ngrams = [(1, 1), (2, 2), (1, 2), (1, 3)]\n",
    "text_columns = ['text_no_numerals', 'text_no_sw', 'text_porter_stemmed', 'text_lancaster_stemmed', 'text_lemmatized']\n",
    "vectorizers = [TfidfVectorizer, CountVectorizer]\n",
    "models = [DecisionTreeClassifier()]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "set decision tree parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'criterion': ['gini',],\n",
    "    'max_depth': [5, 10, 30],\n",
    "    'max_features': ['sqrt', 'log2'],\n",
    "    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainModels(df, targets, vocab_sizes, text_columns, ngrams, vectorizers, models, param_grid):\n",
    "    param_tracker = []\n",
    "    predictions_tracker = []\n",
    "    counter = 1\n",
    "    for size in tqdm(vocab_sizes):\n",
    "#         print(f'vocab size: {size}')\n",
    "\n",
    "\n",
    "        for col in text_columns:\n",
    "#                 print(f'processing method: {col}')\n",
    "\n",
    "\n",
    "            for ng in ngrams:\n",
    "\n",
    "                for vectorizer in vectorizers:\n",
    "                    for model in models:\n",
    "                        vectorizer_name = str(vectorizer).split('.')[-1].replace('>', '').replace(\"\\'\",'').strip()\n",
    "                        model_name = str(model)\n",
    "                        counter+=1\n",
    "                        if counter % 10==0:\n",
    "                            print(f'{counter}')\n",
    "                        vectorizer = vectorizer(max_features=size, ngram_range=ng)\n",
    "\n",
    "                        BOW = vectorizer.fit_transform(df[col])\n",
    "                        BOW_array = BOW.toarray()\n",
    "\n",
    "                        X_train, X_valid, y_train, y_valid = train_test_split(BOW_array, targets, test_size=0.2, random_state=42)\n",
    "\n",
    "#                         print(X_train.shape, X_valid.shape, y_train.shape, y_valid.shape)\n",
    "#                         print(X_train[0])\n",
    "#                         print(y_train)\n",
    "\n",
    "                        grid = RandomizedSearchCV(estimator = model,\n",
    "                                         param_distributions=param_grid,\n",
    "                                         scoring = 'accuracy',\n",
    "                                         cv=3,\n",
    "                                         n_iter=5,\n",
    "                                         verbose=0)\n",
    "\n",
    "                        grid.fit(X_train, y_train)\n",
    "\n",
    "                        accuracy = grid.score(X_valid, y_valid)\n",
    "\n",
    "                        grid_params = grid.best_params_\n",
    "#                         print(grid_params)\n",
    "                        criterion = grid_params['criterion']\n",
    "                        max_depth = grid_params['max_depth']\n",
    "                        max_features = grid_params['max_features']\n",
    "    #                     print(grid_params)\n",
    "#                         print('accuracy: ', accuracy, '\\n')\n",
    "\n",
    "                        model_params = {\n",
    "\n",
    "                            'vocab_size': size,\n",
    "                            'model_name': model_name,\n",
    "                            'text_column': col,\n",
    "                            'ngram': ng,\n",
    "                            'vectorizer': vectorizer_name,\n",
    "                            'splitting_criterion': criterion,\n",
    "                            'tree_max_depth': max_depth,\n",
    "                            'tree_max_features': max_features,\n",
    "                            'accuracy': accuracy\n",
    "\n",
    "\n",
    "                        }\n",
    "    \n",
    "#                         print(model_params)\n",
    "\n",
    "\n",
    "                        param_tracker.append(model_params)\n",
    "\n",
    "\n",
    "            \n",
    "\n",
    "    return param_tracker\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                                                                                                    | 0/3 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "20\n",
      "30\n",
      "40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 33%|████████████████████████████████████████████████████                                                                                                        | 1/3 [00:10<00:21, 10.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50\n",
      "60\n",
      "70\n",
      "80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 67%|████████████████████████████████████████████████████████████████████████████████████████████████████████                                                    | 2/3 [01:53<01:04, 64.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90\n",
      "100\n",
      "110\n",
      "120\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3/3 [34:26<00:00, 688.91s/it]\n"
     ]
    }
   ],
   "source": [
    "param_tracker = trainModels(train_X[:5000], train_y[:5000], vocab_sizes, text_columns, ngrams, vectorizers, models, param_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>vocab_size</th>\n",
       "      <th>model_name</th>\n",
       "      <th>text_column</th>\n",
       "      <th>ngram</th>\n",
       "      <th>vectorizer</th>\n",
       "      <th>splitting_criterion</th>\n",
       "      <th>tree_max_depth</th>\n",
       "      <th>tree_max_features</th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1000</td>\n",
       "      <td>DecisionTreeClassifier()</td>\n",
       "      <td>text_porter_stemmed</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>CountVectorizer</td>\n",
       "      <td>gini</td>\n",
       "      <td>30</td>\n",
       "      <td>None</td>\n",
       "      <td>0.644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10000</td>\n",
       "      <td>DecisionTreeClassifier()</td>\n",
       "      <td>text_porter_stemmed</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>CountVectorizer</td>\n",
       "      <td>gini</td>\n",
       "      <td>30</td>\n",
       "      <td>None</td>\n",
       "      <td>0.644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10000</td>\n",
       "      <td>DecisionTreeClassifier()</td>\n",
       "      <td>text_porter_stemmed</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>CountVectorizer</td>\n",
       "      <td>gini</td>\n",
       "      <td>30</td>\n",
       "      <td>None</td>\n",
       "      <td>0.640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1000</td>\n",
       "      <td>DecisionTreeClassifier()</td>\n",
       "      <td>text_porter_stemmed</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>TfidfVectorizer</td>\n",
       "      <td>gini</td>\n",
       "      <td>30</td>\n",
       "      <td>None</td>\n",
       "      <td>0.638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10000</td>\n",
       "      <td>DecisionTreeClassifier()</td>\n",
       "      <td>text_lancaster_stemmed</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>CountVectorizer</td>\n",
       "      <td>gini</td>\n",
       "      <td>30</td>\n",
       "      <td>None</td>\n",
       "      <td>0.638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>10000</td>\n",
       "      <td>DecisionTreeClassifier()</td>\n",
       "      <td>text_lancaster_stemmed</td>\n",
       "      <td>(2, 2)</td>\n",
       "      <td>CountVectorizer</td>\n",
       "      <td>gini</td>\n",
       "      <td>30</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>0.529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>10000</td>\n",
       "      <td>DecisionTreeClassifier()</td>\n",
       "      <td>text_no_sw</td>\n",
       "      <td>(2, 2)</td>\n",
       "      <td>TfidfVectorizer</td>\n",
       "      <td>gini</td>\n",
       "      <td>10</td>\n",
       "      <td>None</td>\n",
       "      <td>0.527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>1000</td>\n",
       "      <td>DecisionTreeClassifier()</td>\n",
       "      <td>text_lemmatized</td>\n",
       "      <td>(2, 2)</td>\n",
       "      <td>CountVectorizer</td>\n",
       "      <td>gini</td>\n",
       "      <td>30</td>\n",
       "      <td>sqrt</td>\n",
       "      <td>0.525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>1000</td>\n",
       "      <td>DecisionTreeClassifier()</td>\n",
       "      <td>text_no_sw</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>CountVectorizer</td>\n",
       "      <td>gini</td>\n",
       "      <td>30</td>\n",
       "      <td>log2</td>\n",
       "      <td>0.524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>10000</td>\n",
       "      <td>DecisionTreeClassifier()</td>\n",
       "      <td>text_porter_stemmed</td>\n",
       "      <td>(2, 2)</td>\n",
       "      <td>TfidfVectorizer</td>\n",
       "      <td>gini</td>\n",
       "      <td>30</td>\n",
       "      <td>log2</td>\n",
       "      <td>0.518</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>120 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     vocab_size                model_name             text_column   ngram  \\\n",
       "0          1000  DecisionTreeClassifier()     text_porter_stemmed  (1, 2)   \n",
       "1         10000  DecisionTreeClassifier()     text_porter_stemmed  (1, 2)   \n",
       "2         10000  DecisionTreeClassifier()     text_porter_stemmed  (1, 1)   \n",
       "3          1000  DecisionTreeClassifier()     text_porter_stemmed  (1, 1)   \n",
       "4         10000  DecisionTreeClassifier()  text_lancaster_stemmed  (1, 2)   \n",
       "..          ...                       ...                     ...     ...   \n",
       "115       10000  DecisionTreeClassifier()  text_lancaster_stemmed  (2, 2)   \n",
       "116       10000  DecisionTreeClassifier()              text_no_sw  (2, 2)   \n",
       "117        1000  DecisionTreeClassifier()         text_lemmatized  (2, 2)   \n",
       "118        1000  DecisionTreeClassifier()              text_no_sw  (1, 2)   \n",
       "119       10000  DecisionTreeClassifier()     text_porter_stemmed  (2, 2)   \n",
       "\n",
       "          vectorizer splitting_criterion  tree_max_depth tree_max_features  \\\n",
       "0    CountVectorizer                gini              30              None   \n",
       "1    CountVectorizer                gini              30              None   \n",
       "2    CountVectorizer                gini              30              None   \n",
       "3    TfidfVectorizer                gini              30              None   \n",
       "4    CountVectorizer                gini              30              None   \n",
       "..               ...                 ...             ...               ...   \n",
       "115  CountVectorizer                gini              30              sqrt   \n",
       "116  TfidfVectorizer                gini              10              None   \n",
       "117  CountVectorizer                gini              30              sqrt   \n",
       "118  CountVectorizer                gini              30              log2   \n",
       "119  TfidfVectorizer                gini              30              log2   \n",
       "\n",
       "     accuracy  \n",
       "0       0.644  \n",
       "1       0.644  \n",
       "2       0.640  \n",
       "3       0.638  \n",
       "4       0.638  \n",
       "..        ...  \n",
       "115     0.529  \n",
       "116     0.527  \n",
       "117     0.525  \n",
       "118     0.524  \n",
       "119     0.518  \n",
       "\n",
       "[120 rows x 9 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_df = pd.DataFrame(param_tracker,)\n",
    "param_df = param_df.sort_values(by='accuracy', ascending=False).reset_index(drop=True)\n",
    "# param_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# param_df.iloc[0]['vectorizer'].split('.')[-1].replace('>', '').replace(\"\\'\",'').strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>vocab_size</th>\n",
       "      <th>model_name</th>\n",
       "      <th>text_column</th>\n",
       "      <th>ngram</th>\n",
       "      <th>vectorizer</th>\n",
       "      <th>splitting_criterion</th>\n",
       "      <th>tree_max_depth</th>\n",
       "      <th>tree_max_features</th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1000</td>\n",
       "      <td>DecisionTreeClassifier()</td>\n",
       "      <td>text_porter_stemmed</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>CountVectorizer</td>\n",
       "      <td>gini</td>\n",
       "      <td>30</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10000</td>\n",
       "      <td>DecisionTreeClassifier()</td>\n",
       "      <td>text_porter_stemmed</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>CountVectorizer</td>\n",
       "      <td>gini</td>\n",
       "      <td>30</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10000</td>\n",
       "      <td>DecisionTreeClassifier()</td>\n",
       "      <td>text_porter_stemmed</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>CountVectorizer</td>\n",
       "      <td>gini</td>\n",
       "      <td>30</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.640</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   vocab_size                model_name          text_column   ngram  \\\n",
       "0        1000  DecisionTreeClassifier()  text_porter_stemmed  (1, 2)   \n",
       "1       10000  DecisionTreeClassifier()  text_porter_stemmed  (1, 2)   \n",
       "2       10000  DecisionTreeClassifier()  text_porter_stemmed  (1, 1)   \n",
       "\n",
       "        vectorizer splitting_criterion  tree_max_depth tree_max_features  \\\n",
       "0  CountVectorizer                gini              30               NaN   \n",
       "1  CountVectorizer                gini              30               NaN   \n",
       "2  CountVectorizer                gini              30               NaN   \n",
       "\n",
       "   accuracy  \n",
       "0     0.644  \n",
       "1     0.644  \n",
       "2     0.640  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# param_df.to_csv('decision_tree_params.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>vocab_size</th>\n",
       "      <th>model_name</th>\n",
       "      <th>text_column</th>\n",
       "      <th>ngram</th>\n",
       "      <th>vectorizer</th>\n",
       "      <th>splitting_criterion</th>\n",
       "      <th>tree_max_depth</th>\n",
       "      <th>tree_max_features</th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1000</td>\n",
       "      <td>DecisionTreeClassifier()</td>\n",
       "      <td>text_porter_stemmed</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>CountVectorizer</td>\n",
       "      <td>gini</td>\n",
       "      <td>30</td>\n",
       "      <td>None</td>\n",
       "      <td>0.644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10000</td>\n",
       "      <td>DecisionTreeClassifier()</td>\n",
       "      <td>text_porter_stemmed</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>CountVectorizer</td>\n",
       "      <td>gini</td>\n",
       "      <td>30</td>\n",
       "      <td>None</td>\n",
       "      <td>0.644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10000</td>\n",
       "      <td>DecisionTreeClassifier()</td>\n",
       "      <td>text_porter_stemmed</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>CountVectorizer</td>\n",
       "      <td>gini</td>\n",
       "      <td>30</td>\n",
       "      <td>None</td>\n",
       "      <td>0.640</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   vocab_size                model_name          text_column   ngram  \\\n",
       "0        1000  DecisionTreeClassifier()  text_porter_stemmed  (1, 2)   \n",
       "1       10000  DecisionTreeClassifier()  text_porter_stemmed  (1, 2)   \n",
       "2       10000  DecisionTreeClassifier()  text_porter_stemmed  (1, 1)   \n",
       "\n",
       "        vectorizer splitting_criterion  tree_max_depth tree_max_features  \\\n",
       "0  CountVectorizer                gini              30              None   \n",
       "1  CountVectorizer                gini              30              None   \n",
       "2  CountVectorizer                gini              30              None   \n",
       "\n",
       "   accuracy  \n",
       "0     0.644  \n",
       "1     0.644  \n",
       "2     0.640  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_df = pd.read_csv('decision_tree_params.csv')\n",
    "param_df['ngram'] = [(int(ng[1]), int(ng[4])) for ng in param_df['ngram'].values]\n",
    "param_df = param_df.replace({np.nan: None})\n",
    "param_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_20_params = param_df[:20]\n",
    "        \n",
    "k = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                                                                                                   | 0/20 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000 DecisionTreeClassifier() text_porter_stemmed (1, 2) CountVectorizer gini 30 None\n",
      "vectorizing\n",
      "creating BOW\n",
      "splitting train-validation data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  5%|███████▋                                                                                                                                                  | 1/20 [02:10<41:16, 130.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6457359868231466 \n",
      "\n",
      "\n",
      "10000 DecisionTreeClassifier() text_porter_stemmed (1, 2) CountVectorizer gini 30 None\n",
      "vectorizing\n",
      "creating BOW\n",
      "splitting train-validation data\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model_accuracy = []\n",
    "predictions = []\n",
    "for i, param_set in enumerate(tqdm(top_20_params.values)):\n",
    "    (vocab_size, \n",
    "     model_type, \n",
    "     text_column, \n",
    "     ngram, \n",
    "     vectorizer, \n",
    "     criterion, \n",
    "     max_depth,\n",
    "     max_features, \n",
    "     *_) = param_set\n",
    "    \n",
    "    \n",
    "    #     'criterion': ['gini', 'entropy',],\n",
    "    #     'max_depth': [5, 10, 50],\n",
    "    #     'max_features': ['sqrt', 'log2', None],\n",
    "    \n",
    "    \n",
    "    print(vocab_size, model_type, text_column, ngram, vectorizer, criterion, max_depth, max_features)\n",
    "    \n",
    "    if vocab_size:\n",
    "        vocab_size = int(vocab_size)\n",
    "        \n",
    "    # vectorizers = [TfidfVectorizer, CountVectorizer]\n",
    "        \n",
    "    if vectorizer == 'TfidfVectorizer':\n",
    "        vectorizer = TfidfVectorizer\n",
    "    elif vectorizer == 'CountVectorizer':\n",
    "        vectorizer = CountVectorizer\n",
    "\n",
    "    else:\n",
    "        print('warning, unrecognized vectorizer!')\n",
    "        print(i, param_set)\n",
    "    \n",
    "    print('vectorizing')\n",
    "    model_vectorizer = vectorizer(max_features=vocab_size, ngram_range=ngram)\n",
    "\n",
    "    print('creating BOW')\n",
    "    \n",
    "    BOW = model_vectorizer.fit_transform(train_X[text_column])\n",
    "    BOW_array = BOW.toarray()\n",
    "    \n",
    "    print('splitting train-validation data')\n",
    "    \n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "    kfolds = KFold(n_splits=k)\n",
    "    model = DecisionTreeClassifier(criterion=criterion, max_depth=max_depth, max_features=max_features)\n",
    "    \n",
    "    acc_score = []\n",
    "    for train_index , valid_index in kfolds.split(BOW_array):\n",
    "        X_train , X_test = BOW_array[train_index,:],BOW_array[valid_index,:]\n",
    "        y_train , y_test = train_y[train_index] , train_y[valid_index]\n",
    "        \n",
    "        model.fit(X_train[:20_000],y_train[:20_000])\n",
    "        pred_values = model.predict(X_test)\n",
    "\n",
    "        acc = accuracy_score(pred_values , y_test)\n",
    "        acc_score.append(acc)\n",
    "        \n",
    "        pred_probs = model.predict_proba(X_test)\n",
    "\n",
    "    mean_acc = sum(acc_score)/len(acc_score)\n",
    "    \n",
    "    print(mean_acc, '\\n\\n')\n",
    "    model_accuracy.append(mean_acc)\n",
    "    predictions.append(pred_probs)\n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "    \n",
    "    \n",
    "  \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_20_params['acc2'] = model_accuracy\n",
    "top_20_params = top_20_params.sort_values(by='acc2', ascending=False).reset_index(drop=True)\n",
    "top_20_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_20_params.to_csv('decision_tree_top_20_params.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "repeat tuning one last time with top 3 parameter combos and more data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_3_params = top_20_params[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model_accuracy = []\n",
    "top_3_predictions = []\n",
    "for i, param_set in enumerate(tqdm(top_3_params.values)):\n",
    "    (vocab_size, \n",
    "     model_type, \n",
    "     text_column, \n",
    "     ngram, \n",
    "     vectorizer, \n",
    "     criterion, \n",
    "     max_depth,\n",
    "     max_features, \n",
    "     *_) = param_set\n",
    "    \n",
    "    \n",
    "    #     'criterion': ['gini', 'entropy',],\n",
    "    #     'max_depth': [5, 10, 50],\n",
    "    #     'max_features': ['sqrt', 'log2', None],\n",
    "    \n",
    "    \n",
    "    print(vocab_size, model_type, text_column, ngram, vectorizer, criterion, max_depth, max_features)\n",
    "    \n",
    "    if vocab_size:\n",
    "        vocab_size = int(vocab_size)\n",
    "        \n",
    "    # vectorizers = [TfidfVectorizer, CountVectorizer]\n",
    "        \n",
    "    if vectorizer == 'TfidfVectorizer':\n",
    "        vectorizer = TfidfVectorizer\n",
    "    elif vectorizer == 'CountVectorizer':\n",
    "        vectorizer = CountVectorizer\n",
    "\n",
    "    else:\n",
    "        print('warning, unrecognized vectorizer!')\n",
    "        print(i, param_set)\n",
    "    \n",
    "    print('vectorizing')\n",
    "    model_vectorizer = vectorizer(max_features=vocab_size, ngram_range=ngram)\n",
    "\n",
    "    print('creating BOW')\n",
    "    \n",
    "    BOW = model_vectorizer.fit_transform(train_X[text_column])\n",
    "    BOW_array = BOW.toarray()\n",
    "    \n",
    "    print('splitting train-validation data')\n",
    "    \n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "    kfolds = KFold(n_splits=k)\n",
    "    model = DecisionTreeClassifier(criterion=criterion, max_depth=max_depth, max_features=max_features)\n",
    "    \n",
    "    acc_score = []\n",
    "    for train_index , valid_index in kfolds.split(BOW_array):\n",
    "        X_train , X_test = BOW_array[train_index,:],BOW_array[valid_index,:]\n",
    "        y_train , y_test = train_y[train_index] , train_y[valid_index]\n",
    "        \n",
    "        model.fit(X_train[:],y_train[:])\n",
    "        pred_values = model.predict(X_test)\n",
    "\n",
    "        acc = accuracy_score(pred_values , y_test)\n",
    "        acc_score.append(acc)\n",
    "        \n",
    "        pred_probs = model.predict_proba(X_test)\n",
    "\n",
    "    mean_acc = sum(acc_score)/len(acc_score)\n",
    "    \n",
    "    print(mean_acc, '\\n\\n')\n",
    "    model_accuracy.append(mean_acc)\n",
    "    top_3_predictions.append(pred_probs)\n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "    \n",
    "    \n",
    "  \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_3_params['acc3'] = model_accuracy\n",
    "top_3_params = top_3_params.sort_values(by='acc3', ascending=False).reset_index(drop=True)\n",
    "top_3_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_3_params.to_csv('decision_tree_top_3_params.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
