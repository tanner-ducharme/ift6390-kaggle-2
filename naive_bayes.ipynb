{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "import string\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.experimental import enable_halving_search_cv  # noqa\n",
    "from sklearn.model_selection import HalvingRandomSearchCV\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_path = 'data/input/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_train_data = pd.read_csv(input_path + 'train_data_prepped.csv').fillna('')\n",
    "test = pd.read_csv(input_path + 'test_data_prepped.csv').fillna('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>cat</th>\n",
       "      <th>text_no_punc</th>\n",
       "      <th>text_no_numerals</th>\n",
       "      <th>text_no_sw</th>\n",
       "      <th>text_porter_stemmed</th>\n",
       "      <th>text_lancaster_stemmed</th>\n",
       "      <th>text_lemmatized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>anyway im getting of for a while</td>\n",
       "      <td>train</td>\n",
       "      <td>anyway im getting of for a while</td>\n",
       "      <td>anyway im getting of for a while</td>\n",
       "      <td>anyway im getting</td>\n",
       "      <td>anyway im get</td>\n",
       "      <td>anyway im get</td>\n",
       "      <td>anyway im getting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>my red, apache isn't feelin too well this morn...</td>\n",
       "      <td>train</td>\n",
       "      <td>my red apache isnt feelin too well this mornin...</td>\n",
       "      <td>my red apache isnt feelin too well this mornin...</td>\n",
       "      <td>red apache feelin well morning httpmypictmen</td>\n",
       "      <td>red apach feelin well morn httpmypictmen</td>\n",
       "      <td>red apach feelin wel morn httpmypictmen</td>\n",
       "      <td>red apache feelin well morning httpmypictmen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>@danyelljoy you should be  its great. friday w...</td>\n",
       "      <td>train</td>\n",
       "      <td>danyelljoy you should be  its great friday wil...</td>\n",
       "      <td>danyelljoy you should be  its great friday wil...</td>\n",
       "      <td>danyelljoy great friday great tooooooo</td>\n",
       "      <td>danyelljoy great friday great tooooooo</td>\n",
       "      <td>danyelljoy gre friday gre tooooooo</td>\n",
       "      <td>danyelljoy great friday great tooooooo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>its 11:30pm and i dont wanna sleep; so i debat...</td>\n",
       "      <td>train</td>\n",
       "      <td>its 1130pm and i dont wanna sleep so i debated...</td>\n",
       "      <td>its pm and i dont wanna sleep so i debated wit...</td>\n",
       "      <td>pm wanna sleep debated end decided perfect tim...</td>\n",
       "      <td>pm wanna sleep debat end decid perfect time ba...</td>\n",
       "      <td>pm wann sleep deb end decid perfect tim bake! kid</td>\n",
       "      <td>pm wanna sleep debated end decided perfect tim...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>why does twitter eat my dm's?  not happy</td>\n",
       "      <td>train</td>\n",
       "      <td>why does twitter eat my dms?  not happy</td>\n",
       "      <td>why does twitter eat my dms?  not happy</td>\n",
       "      <td>twitter eat dms? happy</td>\n",
       "      <td>twitter eat dms? happi</td>\n",
       "      <td>twit eat dms? happy</td>\n",
       "      <td>twitter eat dms? happy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                               text    cat  \\\n",
       "0   0                  anyway im getting of for a while   train   \n",
       "1   1  my red, apache isn't feelin too well this morn...  train   \n",
       "2   2  @danyelljoy you should be  its great. friday w...  train   \n",
       "3   3  its 11:30pm and i dont wanna sleep; so i debat...  train   \n",
       "4   4          why does twitter eat my dm's?  not happy   train   \n",
       "\n",
       "                                        text_no_punc  \\\n",
       "0                  anyway im getting of for a while    \n",
       "1  my red apache isnt feelin too well this mornin...   \n",
       "2  danyelljoy you should be  its great friday wil...   \n",
       "3  its 1130pm and i dont wanna sleep so i debated...   \n",
       "4           why does twitter eat my dms?  not happy    \n",
       "\n",
       "                                    text_no_numerals  \\\n",
       "0                  anyway im getting of for a while    \n",
       "1  my red apache isnt feelin too well this mornin...   \n",
       "2  danyelljoy you should be  its great friday wil...   \n",
       "3  its pm and i dont wanna sleep so i debated wit...   \n",
       "4           why does twitter eat my dms?  not happy    \n",
       "\n",
       "                                          text_no_sw  \\\n",
       "0                                  anyway im getting   \n",
       "1       red apache feelin well morning httpmypictmen   \n",
       "2             danyelljoy great friday great tooooooo   \n",
       "3  pm wanna sleep debated end decided perfect tim...   \n",
       "4                             twitter eat dms? happy   \n",
       "\n",
       "                                 text_porter_stemmed  \\\n",
       "0                                      anyway im get   \n",
       "1           red apach feelin well morn httpmypictmen   \n",
       "2             danyelljoy great friday great tooooooo   \n",
       "3  pm wanna sleep debat end decid perfect time ba...   \n",
       "4                             twitter eat dms? happi   \n",
       "\n",
       "                              text_lancaster_stemmed  \\\n",
       "0                                      anyway im get   \n",
       "1            red apach feelin wel morn httpmypictmen   \n",
       "2                 danyelljoy gre friday gre tooooooo   \n",
       "3  pm wann sleep deb end decid perfect tim bake! kid   \n",
       "4                                twit eat dms? happy   \n",
       "\n",
       "                                     text_lemmatized  \n",
       "0                                  anyway im getting  \n",
       "1       red apache feelin well morning httpmypictmen  \n",
       "2             danyelljoy great friday great tooooooo  \n",
       "3  pm wanna sleep debated end decided perfect tim...  \n",
       "4                             twitter eat dms? happy  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>cat</th>\n",
       "      <th>text_no_punc</th>\n",
       "      <th>text_no_numerals</th>\n",
       "      <th>text_no_sw</th>\n",
       "      <th>text_porter_stemmed</th>\n",
       "      <th>text_lancaster_stemmed</th>\n",
       "      <th>text_lemmatized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [id, text, cat, text_no_punc, text_no_numerals, text_no_sw, text_porter_stemmed, text_lancaster_stemmed, text_lemmatized]\n",
       "Index: []"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_train_data[all_train_data.isnull().any(axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>cat</th>\n",
       "      <th>text_no_punc</th>\n",
       "      <th>text_no_numerals</th>\n",
       "      <th>text_no_sw</th>\n",
       "      <th>text_porter_stemmed</th>\n",
       "      <th>text_lancaster_stemmed</th>\n",
       "      <th>text_lemmatized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [id, text, cat, text_no_punc, text_no_numerals, text_no_sw, text_porter_stemmed, text_lancaster_stemmed, text_lemmatized]\n",
       "Index: []"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test[test.isnull().any(axis=1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "load train targets, binarize, drop nuetrals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "positive    520436\n",
       "negative    519803\n",
       "neutral         84\n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_results = pd.read_csv(input_path + 'train_results.csv')\n",
    "train_results['target'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id    target\n",
       "0   0  positive\n",
       "1   1  negative\n",
       "2   2  positive\n",
       "3   3  positive\n",
       "4   4  negative"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_train_data['target'] = train_results['target']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "drop nuetral target rows to keep it binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    520436\n",
       "0    519803\n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_train_data = all_train_data[all_train_data['target'] != 'neutral']\n",
    "all_train_data['target'] = [1 if t=='positive' else 0 for t in all_train_data['target'].values]\n",
    "all_train_data['target'].value_counts()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### prepare bag of words<br>\n",
    "we need a different model for each text format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Naive Bayes doesn't have any hyperparameters, so we'll test different versions of the text processing with different versions of naive bayes and corpos generation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the following parameters will be tested<br>\n",
    "1. size of corpus vocab\n",
    "2. corpus ngram varieties\n",
    "3. bernoulli, multinomial or gaussian naive bayes\n",
    "4. stemming/lemmatizing methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_sizes = [100, 1_000, 10_000, None]\n",
    "ngrams = [(1, 1), (2, 2), (1, 2), (1, 3)]\n",
    "models = [BernoulliNB(), GaussianNB(), MultinomialNB()]\n",
    "text_columns = ['text_no_numerals', 'text_no_sw', 'text_porter_stemmed', 'text_lancaster_stemmed', 'text_lemmatized']\n",
    "threshold = 0.5\n",
    "\n",
    "# shuffle train data\n",
    "all_train_data = all_train_data.sample(len(all_train_data))\n",
    "\n",
    "# get data and target\n",
    "train_X = all_train_data.iloc[:, :-1]\n",
    "train_y  = all_train_data.iloc[:, -1]\n",
    "\n",
    "\n",
    "# get 5000 data points for first round of training\n",
    "train_v1 = train_X[:5000]\n",
    "targets_v1 = train_y[:5000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "691997    0\n",
       "176283    1\n",
       "359235    1\n",
       "993260    0\n",
       "209133    0\n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets_v1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainModels(df, targets, vocab_sizes, models, text_columns, ngrams, threshold):\n",
    "\n",
    "    param_tracker = []\n",
    "    counter = 1\n",
    "    for size in tqdm(vocab_sizes):\n",
    "#         print(f'vocab size: {size}')\n",
    "\n",
    "        for model in tqdm(models):\n",
    "#             print(f'model type: {model}')\n",
    "\n",
    "            for col in tqdm(text_columns):\n",
    "#                 print(f'processing method: {col}')\n",
    "\n",
    "\n",
    "                for ng in tqdm(ngrams):\n",
    "#                     print(f'ngram range: {ng}')\n",
    "\n",
    "                    counter+=1\n",
    "                    if counter % 10==0:\n",
    "                        print(f'{counter}')\n",
    "                    vectorizer = CountVectorizer(max_features=size, ngram_range=ng)\n",
    "\n",
    "#                     print('creating bag of words')\n",
    "                    BOW = vectorizer.fit_transform(df[col])\n",
    "                    BOW_array = BOW.toarray()\n",
    "\n",
    "                    X_train, X_valid, y_train, y_valid = train_test_split(BOW_array, targets, test_size=0.2, random_state=42)\n",
    "#                     print('fitting data')      \n",
    "                    model.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "                    prob_predictions = model.predict_proba(X_valid)\n",
    "\n",
    "                    # gets index of 1 column in prob_predictions\n",
    "                    pos_predictions = [pred[list(model.classes_).index(1)] for pred in prob_predictions]\n",
    "\n",
    "                    num_correct_pred = 0\n",
    "                    for pred, actual in zip(pos_predictions, y_valid):\n",
    "                        if pred >= threshold:\n",
    "                            binary_pred = 1\n",
    "                        else:\n",
    "                            binary_pred = 0\n",
    "\n",
    "                        if binary_pred==actual:\n",
    "                            num_correct_pred+=1\n",
    "                    accuracy = num_correct_pred / len(y_valid)\n",
    "#                     print(f'accuracy: {accuracy}')\n",
    "#                     print('\\n\\n')\n",
    "\n",
    "                    param_tracker.append((size, str(model), col, ng, accuracy))\n",
    "                    \n",
    "    param_df = pd.DataFrame(param_tracker, columns = ['vocab_size', 'model_type', 'text_column', 'ngram', 'accuracy'])\n",
    "    param_df = param_df.sort_values(by='accuracy', ascending=False)\n",
    "    return param_df\n",
    "\n",
    "                    \n",
    "                \n",
    "    # for vocab size we'll test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "param_df = trainModels(train_v1, targets_v1, vocab_sizes, models, text_columns, ngrams, threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_df[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# param_df.to_csv('data/output/naive_bayes_params.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_df = pd.read_csv('data/output/naive_bayes_params.csv')\n",
    "\n",
    "# ngrams get saved as string, convert back to int tuple\n",
    "param_df['ngram'] = [(int(ng[1]), int(ng[4])) for ng in param_df['ngram'].values]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "based on these results, we'll train the full dataset on these 20 combinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_params = param_df[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_points = 100_000\n",
    "num_train = int(num_points*0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "full_data_accuracy = []\n",
    "for i, param_set in enumerate(tqdm(top_20.values)):\n",
    "    vocab_size, model_type, text_column, ngram, _ = param_set\n",
    "    print(vocab_size, model_type, text_column, ngram,)\n",
    "    \n",
    "    print('splitting train-validation data')\n",
    "    \n",
    "    # train is all training data with targets included!\n",
    "    train = train.sample(len(train))\n",
    "    training_data = train_X.iloc[:num_points]\n",
    "    targets  = train_y.iloc[:num_points]\n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "   \n",
    "    \n",
    "#     print(len(X_train), len(y_train), len(X_valid), len(y_valid))\n",
    "    \n",
    "    if vocab_size:\n",
    "        vocab_size = int(vocab_size)\n",
    "    \n",
    "    if model_type == 'MultinomialNB()':\n",
    "        model = MultinomialNB()\n",
    "    elif model_type == 'BernoulliNB()':\n",
    "        model = BernoulliNB()\n",
    "    elif model_type == 'GaussianNB()':\n",
    "        model = GaussianNB()\n",
    "    else:\n",
    "        print('warning, unrecognized model!')\n",
    "        print(i, param_set)\n",
    "        \n",
    "    print('vectorizing')\n",
    "    vectorizer = CountVectorizer(max_features=vocab_size, ngram_range=ngram)\n",
    "\n",
    "    print('creating BOW')\n",
    "    \n",
    "    BOW = vectorizer.fit_transform(training_data[text_column])\n",
    "    BOW_array = BOW.toarray()\n",
    "    \n",
    "    X_train = BOW_array[:num_train]\n",
    "    y_train = training_targets[:num_train]\n",
    "    \n",
    "    X_valid = BOW_array[num_train:]\n",
    "    y_valid = training_targets[num_train:]\n",
    "    \n",
    "    \n",
    "    \n",
    "    #     X_train, X_valid, y_train, y_valid = train_test_split(BOW_array, train_y, test_size=0.2, random_state=42)\n",
    "    \n",
    "    print('fitting model')\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    print('getting predictions')\n",
    "    prob_predictions = model.predict_proba(X_valid)\n",
    "\n",
    "    # gets index of 1 column in prob_predictions\n",
    "    pos_predictions = [pred[list(model.classes_).index(1)] for pred in prob_predictions]\n",
    "    \n",
    "    \n",
    "    # get accuracy\n",
    "    num_correct_pred = 0\n",
    "    for pred, actual in zip(pos_predictions, y_valid):\n",
    "        if pred >= threshold:\n",
    "            binary_pred = 1\n",
    "        else:\n",
    "            binary_pred = 0\n",
    "\n",
    "        if binary_pred==actual:\n",
    "            num_correct_pred+=1\n",
    "    accuracy = num_correct_pred / len(y_valid)\n",
    "    print(accuracy)\n",
    "    print('\\n')\n",
    "    \n",
    "    full_data_accuracy.append(accuracy)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_20['final_validation_acc'] = full_data_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_20.to_csv('top_20_naive_bayes.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## train final model with best parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#10000.0 BernoulliNB() text_lemmatized (1, 2)\n",
    "\n",
    "print('vectorizing')\n",
    "vectorizer = CountVectorizer(max_features=10000, ngram_range=(1, 2))\n",
    "\n",
    "print('creating BOW')\n",
    "\n",
    "BOW = vectorizer.fit_transform(training_data['text_lemmatized'])\n",
    "BOW_array = BOW.toarray()\n",
    "\n",
    "\n",
    "model = BernoulliNB()\n",
    "model.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
