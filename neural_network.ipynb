{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-29 16:44:36.465713: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras import layers\n",
    "from keras import regularizers\n",
    "from keras import backend as K\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sagemaker\n",
    "import os\n",
    "from sagemaker.tensorflow import TensorFlow\n",
    "import time\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_path = 'data/input/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_train_data = pd.read_csv(input_path + 'train_data_prepped.csv').fillna('')\n",
    "all_test_data = pd.read_csv(input_path + 'test_data_prepped.csv').fillna('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "positive    520436\n",
       "negative    519803\n",
       "neutral         84\n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_target = pd.read_csv(input_path + 'train_results.csv')\n",
    "train_target['target'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_target['target'] = [0 if t == 'negative' else 2 if t == 'positive' else 2 for t in train_target['target'].values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_train_data['target'] = train_target['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>cat</th>\n",
       "      <th>text_no_punc</th>\n",
       "      <th>text_no_numerals</th>\n",
       "      <th>text_no_sw</th>\n",
       "      <th>text_porter_stemmed</th>\n",
       "      <th>text_lancaster_stemmed</th>\n",
       "      <th>text_lemmatized</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>anyway im getting of for a while</td>\n",
       "      <td>train</td>\n",
       "      <td>anyway im getting of for a while</td>\n",
       "      <td>anyway im getting of for a while</td>\n",
       "      <td>anyway im getting</td>\n",
       "      <td>anyway im get</td>\n",
       "      <td>anyway im get</td>\n",
       "      <td>anyway im getting</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>my red, apache isn't feelin too well this morn...</td>\n",
       "      <td>train</td>\n",
       "      <td>my red apache isnt feelin too well this mornin...</td>\n",
       "      <td>my red apache isnt feelin too well this mornin...</td>\n",
       "      <td>red apache feelin well morning httpmypictmen</td>\n",
       "      <td>red apach feelin well morn httpmypictmen</td>\n",
       "      <td>red apach feelin wel morn httpmypictmen</td>\n",
       "      <td>red apache feelin well morning httpmypictmen</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>@danyelljoy you should be  its great. friday w...</td>\n",
       "      <td>train</td>\n",
       "      <td>danyelljoy you should be  its great friday wil...</td>\n",
       "      <td>danyelljoy you should be  its great friday wil...</td>\n",
       "      <td>danyelljoy great friday great tooooooo</td>\n",
       "      <td>danyelljoy great friday great tooooooo</td>\n",
       "      <td>danyelljoy gre friday gre tooooooo</td>\n",
       "      <td>danyelljoy great friday great tooooooo</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>its 11:30pm and i dont wanna sleep; so i debat...</td>\n",
       "      <td>train</td>\n",
       "      <td>its 1130pm and i dont wanna sleep so i debated...</td>\n",
       "      <td>its pm and i dont wanna sleep so i debated wit...</td>\n",
       "      <td>pm wanna sleep debated end decided perfect tim...</td>\n",
       "      <td>pm wanna sleep debat end decid perfect time ba...</td>\n",
       "      <td>pm wann sleep deb end decid perfect tim bake! kid</td>\n",
       "      <td>pm wanna sleep debated end decided perfect tim...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>why does twitter eat my dm's?  not happy</td>\n",
       "      <td>train</td>\n",
       "      <td>why does twitter eat my dms ?   not happy</td>\n",
       "      <td>why does twitter eat my dms ?   not happy</td>\n",
       "      <td>twitter eat dms ? happy</td>\n",
       "      <td>twitter eat dm ? happi</td>\n",
       "      <td>twit eat dms ? happy</td>\n",
       "      <td>twitter eat dm ? happy</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                               text    cat  \\\n",
       "0   0                  anyway im getting of for a while   train   \n",
       "1   1  my red, apache isn't feelin too well this morn...  train   \n",
       "2   2  @danyelljoy you should be  its great. friday w...  train   \n",
       "3   3  its 11:30pm and i dont wanna sleep; so i debat...  train   \n",
       "4   4          why does twitter eat my dm's?  not happy   train   \n",
       "\n",
       "                                        text_no_punc  \\\n",
       "0                  anyway im getting of for a while    \n",
       "1  my red apache isnt feelin too well this mornin...   \n",
       "2  danyelljoy you should be  its great friday wil...   \n",
       "3  its 1130pm and i dont wanna sleep so i debated...   \n",
       "4         why does twitter eat my dms ?   not happy    \n",
       "\n",
       "                                    text_no_numerals  \\\n",
       "0                  anyway im getting of for a while    \n",
       "1  my red apache isnt feelin too well this mornin...   \n",
       "2  danyelljoy you should be  its great friday wil...   \n",
       "3  its pm and i dont wanna sleep so i debated wit...   \n",
       "4         why does twitter eat my dms ?   not happy    \n",
       "\n",
       "                                          text_no_sw  \\\n",
       "0                                  anyway im getting   \n",
       "1       red apache feelin well morning httpmypictmen   \n",
       "2             danyelljoy great friday great tooooooo   \n",
       "3  pm wanna sleep debated end decided perfect tim...   \n",
       "4                            twitter eat dms ? happy   \n",
       "\n",
       "                                 text_porter_stemmed  \\\n",
       "0                                      anyway im get   \n",
       "1           red apach feelin well morn httpmypictmen   \n",
       "2             danyelljoy great friday great tooooooo   \n",
       "3  pm wanna sleep debat end decid perfect time ba...   \n",
       "4                             twitter eat dm ? happi   \n",
       "\n",
       "                              text_lancaster_stemmed  \\\n",
       "0                                      anyway im get   \n",
       "1            red apach feelin wel morn httpmypictmen   \n",
       "2                 danyelljoy gre friday gre tooooooo   \n",
       "3  pm wann sleep deb end decid perfect tim bake! kid   \n",
       "4                               twit eat dms ? happy   \n",
       "\n",
       "                                     text_lemmatized  target  \n",
       "0                                  anyway im getting       2  \n",
       "1       red apache feelin well morning httpmypictmen       0  \n",
       "2             danyelljoy great friday great tooooooo       2  \n",
       "3  pm wanna sleep debated end decided perfect tim...       2  \n",
       "4                             twitter eat dm ? happy       0  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_train_data['text_num_chars'] = [len(text) for text in all_train_data['text'].values]\n",
    "# all_train_data['text_num_chars'].hist()\n",
    "# all_train_data['text_num_chars'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 40\n",
    "max_words = 100\n",
    "max_len = 200\n",
    "# gpu_count = args.gpu_count\n",
    "# model_dir = args.model_dir\n",
    "# training_di = args.train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = all_train_data['target'].values\n",
    "labels = tf.keras.utils.to_categorical(labels, 3, dtype=\"float32\")\n",
    "features = all_train_data['text_lemmatized'].values\n",
    "X = []\n",
    "for i in range(len(features)):\n",
    "    X.append(str(features[i]))\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tokenizing data and making them sequences\n",
    "tokenizer = Tokenizer(num_words=max_words)\n",
    "tokenizer.fit_on_texts(X)\n",
    "sequences = tokenizer.texts_to_sequences(X)\n",
    "features = pad_sequences(sequences, maxlen=max_len)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer()\n",
    "train_vectors = vectorizer.fit_transform(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1040323, 200)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "75000 25000 75000 25000\n",
      "<class 'numpy.ndarray'> <class 'numpy.ndarray'> <class 'numpy.ndarray'> <class 'numpy.ndarray'>\n",
      "(75000, 200) (25000, 200) (75000, 3) (25000, 3)\n"
     ]
    }
   ],
   "source": [
    "#Splitting the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(features[:100_000], labels[:100_000], random_state=0)\n",
    "X_train = np.asarray(X_train)\n",
    "X_test = np.asarray(X_test)\n",
    "print (len(X_train),len(X_test),len(y_train),len(y_test))\n",
    "print(type(X_train), type(X_test), type(y_train), type(y_test))\n",
    "\n",
    "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0,  0,  0, ...,  0, 15, 75],\n",
       "       [ 0,  0,  0, ...,  0,  4, 55],\n",
       "       [ 0,  0,  0, ..., 56, 61,  5],\n",
       "       ...,\n",
       "       [ 0,  0,  0, ...,  0,  0, 40],\n",
       "       [ 0,  0,  0, ..., 21, 87, 10],\n",
       "       [ 0,  0,  0, ...,  0,  0,  0]], dtype=int32)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-24 14:37:46.057426: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "# Building the model\n",
    "model = Sequential()\n",
    "model.add(layers.Embedding(max_words, 40, input_length=max_len))\n",
    "model.add(layers.Bidirectional(layers.LSTM(20,dropout=0.6)))\n",
    "model.add(layers.Dense(3,activation='softmax'))\n",
    "model.compile(optimizer='rmsprop',loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "2344/2344 [==============================] - 118s 49ms/step - loss: 0.6315 - accuracy: 0.6241 - val_loss: 0.6048 - val_accuracy: 0.6545\n",
      "Epoch 2/5\n",
      "2344/2344 [==============================] - 110s 47ms/step - loss: 0.6111 - accuracy: 0.6452 - val_loss: 0.6032 - val_accuracy: 0.6569\n",
      "Epoch 3/5\n",
      "2344/2344 [==============================] - 127s 54ms/step - loss: 0.6104 - accuracy: 0.6455 - val_loss: 0.6024 - val_accuracy: 0.6567\n",
      "Epoch 4/5\n",
      "2344/2344 [==============================] - 159s 68ms/step - loss: 0.6100 - accuracy: 0.6462 - val_loss: 0.6023 - val_accuracy: 0.6557\n",
      "Epoch 5/5\n",
      "2344/2344 [==============================] - 126s 54ms/step - loss: 0.6099 - accuracy: 0.6466 - val_loss: 0.6021 - val_accuracy: 0.6561\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, epochs=5,validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 - 9s - loss: 0.4968 - accuracy: 0.7555 - 9s/epoch - 11ms/step\n",
      "Model accuracy:  0.7555199861526489\n"
     ]
    }
   ],
   "source": [
    "#Validating model\n",
    "test_loss, test_acc = model.evaluate(X_test, y_test, verbose=2)\n",
    "print('Model accuracy: ',test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 [==============================] - 10s 12ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[4.5558226e-01, 1.8222425e-05, 5.4439950e-01],\n",
       "       [9.4461894e-01, 1.1016793e-06, 5.5379920e-02],\n",
       "       [3.6494431e-01, 2.3243065e-05, 6.3503242e-01],\n",
       "       ...,\n",
       "       [9.2991829e-01, 2.0066780e-06, 7.0079714e-02],\n",
       "       [4.1700915e-02, 2.0932944e-06, 9.5829701e-01],\n",
       "       [6.7220174e-02, 3.6591196e-06, 9.3277615e-01]], dtype=float32)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = all_train_data['target'].values\n",
    "labels = tf.keras.utils.to_categorical(labels, 3, dtype=\"float32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_columns = ['text_no_numerals', 'text_no_sw', 'text_porter_stemmed', 'text_lancaster_stemmed', 'text_lemmatized']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "469/469 [==============================] - 34s 64ms/step - loss: 0.6612 - accuracy: 0.5978 - val_loss: 0.5678 - val_accuracy: 0.6996\n",
      "Epoch 2/5\n",
      "469/469 [==============================] - 30s 64ms/step - loss: 0.5378 - accuracy: 0.7289 - val_loss: 0.5267 - val_accuracy: 0.7356\n",
      "Epoch 3/5\n",
      "469/469 [==============================] - 29s 63ms/step - loss: 0.4955 - accuracy: 0.7618 - val_loss: 0.5214 - val_accuracy: 0.7444\n",
      "Epoch 4/5\n",
      "469/469 [==============================] - 29s 63ms/step - loss: 0.4714 - accuracy: 0.7803 - val_loss: 0.5289 - val_accuracy: 0.7392\n",
      "Epoch 5/5\n",
      "469/469 [==============================] - 32s 69ms/step - loss: 0.4572 - accuracy: 0.7871 - val_loss: 0.5111 - val_accuracy: 0.7486\n",
      "157/157 - 2s - loss: 0.5111 - accuracy: 0.7486 - 2s/epoch - 11ms/step\n",
      "column \"text_no_numerals\" Model accuracy: 0.7486000061035156\n",
      "Epoch 1/5\n",
      "469/469 [==============================] - 36s 69ms/step - loss: 0.6769 - accuracy: 0.5815 - val_loss: 0.5848 - val_accuracy: 0.6918\n",
      "Epoch 2/5\n",
      "469/469 [==============================] - 31s 67ms/step - loss: 0.5542 - accuracy: 0.7162 - val_loss: 0.5497 - val_accuracy: 0.7218\n",
      "Epoch 3/5\n",
      "469/469 [==============================] - 34s 73ms/step - loss: 0.5114 - accuracy: 0.7487 - val_loss: 0.5428 - val_accuracy: 0.7298\n",
      "Epoch 4/5\n",
      "469/469 [==============================] - 35s 74ms/step - loss: 0.4913 - accuracy: 0.7638 - val_loss: 0.5420 - val_accuracy: 0.7272\n",
      "Epoch 5/5\n",
      "469/469 [==============================] - 32s 69ms/step - loss: 0.4806 - accuracy: 0.7720 - val_loss: 0.5353 - val_accuracy: 0.7300\n",
      "157/157 - 2s - loss: 0.5353 - accuracy: 0.7300 - 2s/epoch - 11ms/step\n",
      "column \"text_no_sw\" Model accuracy: 0.7300000190734863\n",
      "Epoch 1/5\n",
      "469/469 [==============================] - 35s 68ms/step - loss: 0.6734 - accuracy: 0.5797 - val_loss: 0.5793 - val_accuracy: 0.6980\n",
      "Epoch 2/5\n",
      "469/469 [==============================] - 33s 71ms/step - loss: 0.5494 - accuracy: 0.7175 - val_loss: 0.5470 - val_accuracy: 0.7218\n",
      "Epoch 3/5\n",
      "469/469 [==============================] - 30s 64ms/step - loss: 0.5124 - accuracy: 0.7464 - val_loss: 0.5458 - val_accuracy: 0.7224\n",
      "Epoch 4/5\n",
      "469/469 [==============================] - 32s 69ms/step - loss: 0.4930 - accuracy: 0.7630 - val_loss: 0.5377 - val_accuracy: 0.7300\n",
      "Epoch 5/5\n",
      "469/469 [==============================] - 30s 65ms/step - loss: 0.4811 - accuracy: 0.7716 - val_loss: 0.5412 - val_accuracy: 0.7306\n",
      "157/157 - 2s - loss: 0.5412 - accuracy: 0.7306 - 2s/epoch - 12ms/step\n",
      "column \"text_porter_stemmed\" Model accuracy: 0.7305999994277954\n",
      "Epoch 1/5\n",
      "469/469 [==============================] - 36s 69ms/step - loss: 0.6553 - accuracy: 0.6089 - val_loss: 0.5682 - val_accuracy: 0.7098\n",
      "Epoch 2/5\n",
      "469/469 [==============================] - 30s 64ms/step - loss: 0.5422 - accuracy: 0.7243 - val_loss: 0.5577 - val_accuracy: 0.7188\n",
      "Epoch 3/5\n",
      "469/469 [==============================] - 30s 63ms/step - loss: 0.5130 - accuracy: 0.7477 - val_loss: 0.5449 - val_accuracy: 0.7232\n",
      "Epoch 4/5\n",
      "469/469 [==============================] - 30s 64ms/step - loss: 0.4948 - accuracy: 0.7608 - val_loss: 0.5486 - val_accuracy: 0.7232\n",
      "Epoch 5/5\n",
      "469/469 [==============================] - 31s 66ms/step - loss: 0.4826 - accuracy: 0.7672 - val_loss: 0.5585 - val_accuracy: 0.7254\n",
      "157/157 - 2s - loss: 0.5585 - accuracy: 0.7254 - 2s/epoch - 11ms/step\n",
      "column \"text_lancaster_stemmed\" Model accuracy: 0.7253999710083008\n",
      "Epoch 1/5\n",
      "469/469 [==============================] - 33s 64ms/step - loss: 0.6847 - accuracy: 0.5745 - val_loss: 0.6001 - val_accuracy: 0.6924\n",
      "Epoch 2/5\n",
      "469/469 [==============================] - 30s 64ms/step - loss: 0.5525 - accuracy: 0.7153 - val_loss: 0.5665 - val_accuracy: 0.7052\n",
      "Epoch 3/5\n",
      "469/469 [==============================] - 30s 65ms/step - loss: 0.5126 - accuracy: 0.7467 - val_loss: 0.5414 - val_accuracy: 0.7206\n",
      "Epoch 4/5\n",
      "469/469 [==============================] - 30s 64ms/step - loss: 0.4936 - accuracy: 0.7635 - val_loss: 0.5383 - val_accuracy: 0.7228\n",
      "Epoch 5/5\n",
      "469/469 [==============================] - 31s 66ms/step - loss: 0.4797 - accuracy: 0.7706 - val_loss: 0.5487 - val_accuracy: 0.7240\n",
      "157/157 - 2s - loss: 0.5487 - accuracy: 0.7240 - 2s/epoch - 12ms/step\n",
      "column \"text_lemmatized\" Model accuracy: 0.7239999771118164\n"
     ]
    }
   ],
   "source": [
    "for col in text_columns:\n",
    "#     print(col)\n",
    "    features = all_train_data[col].values\n",
    "    X = []\n",
    "    for i in range(len(features)):\n",
    "        X.append(str(features[i]))\n",
    "    \n",
    "    #Tokenizing data and making them sequences\n",
    "    tokenizer = Tokenizer(num_words=max_words)\n",
    "    tokenizer.fit_on_texts(X)\n",
    "    sequences = tokenizer.texts_to_sequences(X)\n",
    "    features = pad_sequences(sequences, maxlen=max_len)\n",
    "    \n",
    "    #Splitting the data\n",
    "    X_train, X_test, y_train, y_test = train_test_split(features[:20_000], labels[:20_000], random_state=0)\n",
    "    X_train = np.asarray(X_train)\n",
    "    X_test = np.asarray(X_test)\n",
    "    \n",
    "    # Building the model\n",
    "    model = Sequential()\n",
    "    model.add(layers.Embedding(max_words, 40, input_length=max_len))\n",
    "    model.add(layers.Bidirectional(layers.LSTM(20,dropout=0.6)))\n",
    "    model.add(layers.Dense(3,activation='softmax'))\n",
    "    model.compile(optimizer='rmsprop',loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    history = model.fit(X_train, y_train, epochs=5,validation_data=(X_test, y_test))\n",
    "\n",
    "\n",
    "    #Validating model\n",
    "    test_loss, test_acc = model.evaluate(X_test, y_test, verbose=2)\n",
    "    print(f'column \"{col}\" Model accuracy: {test_acc}\\n\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_words = 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = all_train_data['text_no_numerals'].values\n",
    "X = []\n",
    "for i in range(len(features)):\n",
    "    X.append(str(features[i]))\n",
    "\n",
    "#Tokenizing data and making them sequences\n",
    "tokenizer = Tokenizer(num_words=max_words)\n",
    "tokenizer.fit_on_texts(X)\n",
    "sequences = tokenizer.texts_to_sequences(X)\n",
    "features = pad_sequences(sequences, maxlen=max_len)\n",
    "\n",
    "#Splitting the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(features[:20_000], labels[:20_000], random_state=0)\n",
    "X_train = np.asarray(X_train)\n",
    "X_test = np.asarray(X_test)\n",
    "\n",
    "# Building the model\n",
    "model = Sequential()\n",
    "model.add(layers.Embedding(max_words, 40, input_length=max_len))\n",
    "model.add(layers.Bidirectional(layers.LSTM(20,dropout=0.6)))\n",
    "model.add(layers.Dense(3,activation='softmax'))\n",
    "model.compile(optimizer='rmsprop',loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(X_train, y_train, epochs=5,validation_data=(X_test, y_test))\n",
    "\n",
    "\n",
    "#Validating model\n",
    "test_loss, test_acc = model.evaluate(X_test, y_test, verbose=2)\n",
    "print(f'column \"{col}\" Model accuracy: {test_acc}\\n\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## try matrix representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_words=1_000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tokenizing data and making them sequences\n",
    "tokenizer = Tokenizer(num_words=max_words)\n",
    "tokenizer.fit_on_texts(X)\n",
    "sequences = tokenizer.texts_to_matrix(X, mode=\"tfidf\")\n",
    "# features = pad_sequences(sequences, maxlen=max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sequences.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37500 12500 37500 12500\n",
      "<class 'numpy.ndarray'> <class 'numpy.ndarray'> <class 'numpy.ndarray'> <class 'numpy.ndarray'>\n",
      "(37500, 1000) (12500, 1000) (37500, 3) (12500, 3)\n"
     ]
    }
   ],
   "source": [
    "#Splitting the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(sequences[:50_000], labels[:50_000], random_state=0)\n",
    "X_train = np.asarray(X_train)\n",
    "X_test = np.asarray(X_test)\n",
    "print (len(X_train),len(X_test),len(y_train),len(y_test))\n",
    "print(type(X_train), type(X_test), type(y_train), type(y_test))\n",
    "\n",
    "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building the model\n",
    "model = Sequential()\n",
    "model.add(layers.Embedding(max_words, 40, input_length=X_train.shape[1]))\n",
    "model.add(layers.Bidirectional(layers.LSTM(20,dropout=0.6)))\n",
    "model.add(layers.Dense(3,activation='softmax'))\n",
    "model.compile(optimizer='rmsprop',loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(X_train, y_train, epochs=5,validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Validating model\n",
    "test_loss, test_acc = model.evaluate(X_test, y_test, verbose=2)\n",
    "print('Model accuracy: ',test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
