{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-28 16:51:05.838385: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from nltk import FreqDist\n",
    "from collections import Counter\n",
    "from tqdm import tqdm\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras import layers\n",
    "from keras import regularizers\n",
    "from keras import backend as K\n",
    "from keras.callbacks import ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_path = 'data/input/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(input_path + 'train_data_prepped.csv').fillna('')\n",
    "# test_data = pd.read_csv(input_path + 'test_data_prepped.csv').fillna('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "positive    520436\n",
       "negative    519803\n",
       "neutral         84\n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target = pd.read_csv(input_path + 'train_results.csv')\n",
    "target['target'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "target['target'] = [0 if t == 'negative' else 2 if t == 'positive' else 1 for t in target['target'].values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['target'] = target['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.sample(len(data)).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>cat</th>\n",
       "      <th>text_no_punc</th>\n",
       "      <th>text_no_numerals</th>\n",
       "      <th>text_no_sw</th>\n",
       "      <th>text_porter_stemmed</th>\n",
       "      <th>text_lancaster_stemmed</th>\n",
       "      <th>text_lemmatized</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1002697</td>\n",
       "      <td>4 days before i leave manila!</td>\n",
       "      <td>train</td>\n",
       "      <td>4 days before i leave manila!</td>\n",
       "      <td>days before i leave manila!</td>\n",
       "      <td>days leave manila!</td>\n",
       "      <td>day leav manila!</td>\n",
       "      <td>day leav manila!</td>\n",
       "      <td>day leave manila!</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>14839</td>\n",
       "      <td>mmmm twitter online... background changed! i s...</td>\n",
       "      <td>train</td>\n",
       "      <td>mmmm twitter online background changed! i shou...</td>\n",
       "      <td>mmmm twitter online background changed! i shou...</td>\n",
       "      <td>mmmm twitter online background changed! start ...</td>\n",
       "      <td>mmmm twitter onlin background changed! start e...</td>\n",
       "      <td>mmmm twit onlin background changed! start expa...</td>\n",
       "      <td>mmmm twitter online background changed! start ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>461477</td>\n",
       "      <td>1 heroic shattered halls run, 2 savagery formu...</td>\n",
       "      <td>train</td>\n",
       "      <td>1 heroic shattered halls run 2 savagery formul...</td>\n",
       "      <td>heroic shattered halls run  savagery formula ...</td>\n",
       "      <td>heroic shattered halls run savagery formula dr...</td>\n",
       "      <td>heroic shatter hall run savageri formula drop ...</td>\n",
       "      <td>hero shat hal run savagery formul drop woot! s...</td>\n",
       "      <td>heroic shattered hall run savagery formula dro...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>196536</td>\n",
       "      <td>net .. net .. net ..  hmm. bad weather .. weir...</td>\n",
       "      <td>train</td>\n",
       "      <td>net  net  net   hmm bad weather  weird summer!</td>\n",
       "      <td>net  net  net   hmm bad weather  weird summer!</td>\n",
       "      <td>net net net hmm bad weather weird summer!</td>\n",
       "      <td>net net net hmm bad weather weird summer!</td>\n",
       "      <td>net net net hmm bad weath weird summer!</td>\n",
       "      <td>net net net hmm bad weather weird summer!</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>825375</td>\n",
       "      <td>@stephj0 why don't you marry it?    just kiddi...</td>\n",
       "      <td>train</td>\n",
       "      <td>stephj0 why dont you marry it ?     just kiddi...</td>\n",
       "      <td>stephj why dont you marry it ?     just kiddin...</td>\n",
       "      <td>stephj marry ? kidding cant resist junior high...</td>\n",
       "      <td>stephj marri ? kid cant resist junior high hum...</td>\n",
       "      <td>stephs marry ? kid cant resist juny high hum s...</td>\n",
       "      <td>stephj marry ? kidding cant resist junior high...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id                                               text    cat  \\\n",
       "0  1002697                    4 days before i leave manila!    train   \n",
       "1    14839  mmmm twitter online... background changed! i s...  train   \n",
       "2   461477  1 heroic shattered halls run, 2 savagery formu...  train   \n",
       "3   196536  net .. net .. net ..  hmm. bad weather .. weir...  train   \n",
       "4   825375  @stephj0 why don't you marry it?    just kiddi...  train   \n",
       "\n",
       "                                        text_no_punc  \\\n",
       "0                    4 days before i leave manila!     \n",
       "1  mmmm twitter online background changed! i shou...   \n",
       "2  1 heroic shattered halls run 2 savagery formul...   \n",
       "3     net  net  net   hmm bad weather  weird summer!   \n",
       "4  stephj0 why dont you marry it ?     just kiddi...   \n",
       "\n",
       "                                    text_no_numerals  \\\n",
       "0                      days before i leave manila!     \n",
       "1  mmmm twitter online background changed! i shou...   \n",
       "2   heroic shattered halls run  savagery formula ...   \n",
       "3     net  net  net   hmm bad weather  weird summer!   \n",
       "4  stephj why dont you marry it ?     just kiddin...   \n",
       "\n",
       "                                          text_no_sw  \\\n",
       "0                                 days leave manila!   \n",
       "1  mmmm twitter online background changed! start ...   \n",
       "2  heroic shattered halls run savagery formula dr...   \n",
       "3          net net net hmm bad weather weird summer!   \n",
       "4  stephj marry ? kidding cant resist junior high...   \n",
       "\n",
       "                                 text_porter_stemmed  \\\n",
       "0                                   day leav manila!   \n",
       "1  mmmm twitter onlin background changed! start e...   \n",
       "2  heroic shatter hall run savageri formula drop ...   \n",
       "3          net net net hmm bad weather weird summer!   \n",
       "4  stephj marri ? kid cant resist junior high hum...   \n",
       "\n",
       "                              text_lancaster_stemmed  \\\n",
       "0                                   day leav manila!   \n",
       "1  mmmm twit onlin background changed! start expa...   \n",
       "2  hero shat hal run savagery formul drop woot! s...   \n",
       "3            net net net hmm bad weath weird summer!   \n",
       "4  stephs marry ? kid cant resist juny high hum s...   \n",
       "\n",
       "                                     text_lemmatized  target  \n",
       "0                                  day leave manila!       0  \n",
       "1  mmmm twitter online background changed! start ...       2  \n",
       "2  heroic shattered hall run savagery formula dro...       0  \n",
       "3          net net net hmm bad weather weird summer!       2  \n",
       "4  stephj marry ? kidding cant resist junior high...       2  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['num_chars'] = [len(text) for text in data['text']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['num_words'] = [len(text.split()) for text in data['text']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    1.040323e+06\n",
       "mean     7.412928e+01\n",
       "std      3.644499e+01\n",
       "min      6.000000e+00\n",
       "25%      4.400000e+01\n",
       "50%      6.900000e+01\n",
       "75%      1.040000e+02\n",
       "max      3.690000e+02\n",
       "Name: num_chars, dtype: float64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['num_chars'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    1.040323e+06\n",
       "mean     1.318478e+01\n",
       "std      6.959487e+00\n",
       "min      1.000000e+00\n",
       "25%      7.000000e+00\n",
       "50%      1.200000e+01\n",
       "75%      1.900000e+01\n",
       "max      6.400000e+01\n",
       "Name: num_words, dtype: float64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['num_words'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pos = data[data['target']==2]\n",
    "# neg = data[data['target']==0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pos['num_chars'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# neg['num_chars'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pos['num_words'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# neg['num_words'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pos_corpus = ' '.join(list(pos['text_lemmatized'])).split()\n",
    "\n",
    "# neg_corpus = ' '.join(list(neg['text_lemmatized'])).split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fdist_pos = FreqDist(pos_corpus)\n",
    "# fdist_neg = FreqDist(neg_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fdist_pos.most_common()[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fdist_neg.most_common()[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "idea for choosing words: find words with biggest discrepancy between pos class and neg class tf-idf<br>\n",
    "if TF-IDFpos / TF-IDFneg is really high, the word is relatively important to the positive class<br>\n",
    "steps:<br>\n",
    "1. use tfidf vectorizer on train data\n",
    "2. for each word in corpus, get average tfidf for pos class and for neg class\n",
    "3. for each word, get ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# corpus = list(set(' '.join(list(data['text_porter_stemmed'])).split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# corpus[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(max_features = 10_000, ngram_range=(1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = vectorizer.fit_transform(data['text_porter_stemmed']).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_index = data[data['target']==2].index\n",
    "neg_index = data[data['target']==0].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_X = X[pos_index, :]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neg_X = X[neg_index, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neg_X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['target'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_tfidf_avg = np.mean(pos_X, axis=0)\n",
    "neg_tfidf_avg = np.mean(neg_X, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_tfidf_avg.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neg_tfidf_avg.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(vectorizer.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# labels = tf.keras.utils.to_categorical(labels, 3, dtype=\"float32\")\n",
    "features = data['text_lemmatized'].values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_words=10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tokenizing data and making them sequences\n",
    "tokenizer = Tokenizer(num_words=max_words)\n",
    "\n",
    "tokenizer.fit_on_texts(features)\n",
    "\n",
    "X = tokenizer.texts_to_matrix(features, mode='tfidf')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = data['target'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Splitting the data\n",
    "# X_train, X_test, y_train, y_test = train_test_split(features[:100_000], labels[:100_000], random_state=0)\n",
    "# X_train = np.asarray(X_train)\n",
    "# X_test = np.asarray(X_test)\n",
    "# print (len(X_train),len(X_test),len(y_train),len(y_test))\n",
    "# print(type(X_train), type(X_test), type(y_train), type(y_test))\n",
    "\n",
    "# print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = RandomForestClassifier()\n",
    "clf.fit(X[:100_000], labels[:100_000])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importances = clf.feature_importances_\n",
    "importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_order = np.argsort(importances)[::-1]\n",
    "\n",
    "feature_order.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_order\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = tokenizer.word_index\n",
    "feature_key = {index: word for word, index in feature_names.items()}\n",
    "feature_key\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this gets top words by feature importance\n",
    "top_words = []\n",
    "\n",
    "for i in range(1, 1001):\n",
    "    word_key = feature_order[i]\n",
    "    word = feature_key[word_key]\n",
    "    top_words.append(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(top_words).to_csv('top_words.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(top_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "only keep top_words in BOW, then run NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_index = {w:i for i, w in enumerate(top_words)}\n",
    "word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len=200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tokenizing data and making them sequences\n",
    "# tokenizer = Tokenizer(num_words=1000)\n",
    "# tokenizer.word_index = word_index\n",
    "# tokenizer.fit_on_texts(X_raw)\n",
    "# features = tokenizer.texts_to_matrix(X_raw, mode=\"tfidf\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = data['text_lemmatized'].values\n",
    "# vectorizer = TfidfVectorizer(vocabulary=word_index, max_features=len(top_words))\n",
    "vectorizer = TfidfVectorizer(max_features=len(top_words))\n",
    "\n",
    "BOW = vectorizer.fit_transform(features)\n",
    "BOW_array = BOW.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BOW_array.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "one_hot_labels = tf.keras.utils.to_categorical(labels, 3, dtype=\"float32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Splitting the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(BOW_array[:], one_hot_labels[:], random_state=0)\n",
    "X_train = np.asarray(X_train)\n",
    "X_test = np.asarray(X_test)\n",
    "print (len(X_train),len(X_test),len(y_train),len(y_test))\n",
    "print(type(X_train), type(X_test), type(y_train), type(y_test))\n",
    "\n",
    "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building the model\n",
    "model = Sequential()\n",
    "model.add(layers.Embedding(max_words, 40, input_length=1000))\n",
    "model.add(layers.Bidirectional(layers.LSTM(20,dropout=0.6)))\n",
    "model.add(layers.Dense(3,activation='softmax'))\n",
    "model.compile(optimizer='rmsprop',loss='categorical_crossentropy', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(X_train[-100_000:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(X_train[-5_000:], y_train[-5_000:], epochs=5,validation_data=(X_test[:5000], y_test[:5000]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Validating model\n",
    "test_loss, test_acc = model.evaluate(X_test, y_test, verbose=2)\n",
    "print('Model accuracy: ',test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
